+++
title = '连续思考与思考干预：一次可重复的实验记录'
date = 2026-01-17T20:20:00+08:00
tags = ['LLM','Thinking','Intervention','Experiment','Devlog','Web']
author = 'Pectics'
description = '围绕思考标签的干预实验：从单步解码、思考编辑到连续思考暂停与回复预览。'
+++

## 背景与目标

我想测试一个很具体的问题：**当模型思考（`<think>...</think>`）被人类修改时，最终回复是否会沿着“被干预的思考”演化**。这不是“Prompt 是否有效”的问题，而是对“思考与回复之间因果联系”的一次实验。

为了降低主观猜测，我把测试拆成两个层次：

1. **单步解码 + 可编辑思考**：控制每个 token 的生成，让“干预”可以精确发生在思考中途。
2. **连续思考循环**：让模型持续思考到 `</think>` 自动暂停，允许我改写思考后继续“下一轮思考”。

## 实验流程（来自真实对话日志）

我把与 ChatGPT 的实验流程整理在 `testlog/20260117.md`，核心步骤如下：

- 模型先完成一段思考，并在 `</think>` 后生成回复。
- 我把这段回复放回思考里，用 `<response>...</response>` 标记“已回复”。
- 然后继续追加后思考，期待模型“在已回复之后继续深挖”。

日志里的一段片段（简化展示）：

```
<response>
…（模型的回复）…
</response>

好吧，我已经做出了一段回复，但我不禁想到：用户为什么会问这个问题？
```

**现实结果**：模型并没有进入“后思考”，而是快速回到“总结式的回复口吻”。这说明模型很容易被“完成任务”的语义吸附回“回复轨道”，而不是留在思考轨道中。

## 工具构建：从 CLI 到 Web

CLI 版在多轮交互和输入控制上存在明显限制（尤其是单步解码+输入干预时），所以我把实验迁移到 Web：

### 1) 思考干预实验器（thought-intervention-lab）

核心能力：

- **单步生成 1 token**
- **思考区可编辑**，修改后重建解码状态
- **回复预览**（不写入历史，仅显示）

实现上我把 `model.generate` 改为“手动一步一步前向”，保留 `past_key_values`，并在每次生成时只取当前 logits 的 `argmax` 作为下一 token。这样就能把“解码过程”从一口气生成拆成可被操作的“细颗粒过程”。

### 2) 连续思考实验器（continuous-thinking-lab）

这是本次实验的主力工具：

- 输入 Prompt 后自动思考，直到命中 `</think>`
- 暂停后允许修改思考，并“继续下一轮思考”
- **SSE 流式输出**，实时看到思考增长
- **可选择屏蔽 `</think>` 或 EOS**，让思考不被终止符打断
- **回复预览**：到达 `</think>` 时，额外生成一段“真实回复”（只展示、不写入）

为了避免“忽略 `</think>` 但上下文仍然包含它”的问题，我采用的是更严格的做法：

> 当关闭 `</think>` 终止时，直接把 `END_THINK_TOKEN_ID` 的 logits 置为 `-inf`，然后重新取 `argmax`。

这等价于“强制选择次高概率 token”，让模型继续在思考轨道中输出，而不是进入回复模式。

## 关键观察

### 1) 思考终止不完全由 token 控制

即使我屏蔽 `</think>` 和 EOS，模型仍然会在语义层面“切回回复口吻”。这说明：

- 终止不是纯 token 触发
- 语义上的“任务完成感”会吸引模型进入“回复模式”

### 2) 思考内容更像“生成过程中的控制信号”

当我把回复放回思考里，模型并不会继续深入思考，而是把这段内容当作“对话中的完成信号”。这意味着：

- 思考内容本身并不是稳定的推理状态
- 它更像“生成中用于组织输出的文本惯性”

### 3) 需要外部控制器才能实现“后思考”

如果要让模型在“回复之后继续思考”，单靠 Prompt 或 token hack 并不够。更像是需要一个 **外部控制器** 来定义新的目标与停止条件，否则模型会退化为“对话日志续写”。

## 接下来要做的

1. **把“多轮思考片段”记录成时间线**：每次暂停时保存思考片段，观察思维是否逐轮漂移。
2. **加入采样策略（temperature/top-p）**：测试确定性 argmax 是否导致“更快收敛到回复语气”。
3. **做一个“思考约束模板”**：让模型显式标记“继续思考 / 已回复 / 后反思”，看看是否能延长思考寿命。

---

这次实验最让我确定的一点是：**LLM 的“思考”并不是一个稳定可持续的内部状态，而是一个可被语义吸附迅速终止的生成路径**。要想真正让它持续后思考，必须把“目标函数”交给外部系统，而不是靠标签或 token hack。
